{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzM2B90kwngN"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install wandb\n",
        "!pip install kaggle\n",
        "!pip install tqdm matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "id": "zmZRcoPUw9wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "tNngDnBExO9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip challenges-in-representation-learning-facial-expression-recognition-challenge.zip -d data/\n"
      ],
      "metadata": {
        "id": "fP3btaw7xQvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "id": "9bcVpe4axaMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from src.data_loader import FERDataset\n",
        "from src.train import train_model\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "def run_pipeline(model_class, architecture_name, config_dict):\n",
        "    wandb.init(project=\"facial_expression_recognition\", config=config_dict)\n",
        "    wandb.config[\"architecture\"] = architecture_name\n",
        "\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((48, 48)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    train_dataset = FERDataset(csv_file='data/train_split.csv', transform=transform)\n",
        "    val_dataset = FERDataset(csv_file='data/val_split.csv', transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=wandb.config.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    model = model_class()\n",
        "\n",
        "\n",
        "    train_model(model, train_loader, val_loader, wandb.config)\n",
        "\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "id": "8nLLQauTZ5S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.model import SimpleCNN, DeeperCNN\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('data/train.csv')\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['emotion'])\n",
        "\n",
        "train_df.to_csv('data/train_split.csv', index=False)\n",
        "val_df.to_csv('data/val_split.csv', index=False)\n",
        "\n",
        "print(\"Train/val split done.\")\n",
        "\n",
        "\n",
        "\n",
        "run_pipeline(SimpleCNN, \"SimpleCNN\", {\n",
        "    \"epochs\": 15,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 64\n",
        "})\n",
        "\n",
        "\n",
        "run_pipeline(DeeperCNN, \"DeeperCNN\", {\n",
        "    \"epochs\": 25,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 64\n",
        "})\n"
      ],
      "metadata": {
        "id": "7VMADp0Uj-wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.model import ResNet18\n",
        "\n",
        "\n",
        "run_pipeline(ResNet18, \"ResNet18\", {\n",
        "    \"epochs\": 30,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"batch_size\": 64\n",
        "})\n"
      ],
      "metadata": {
        "id": "_g2KQBsZigf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.model import DeeperCNN2\n",
        "\n",
        "run_pipeline(DeeperCNN2, \"DeeperCNN2\", {\n",
        "    \"epochs\": 25,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 64\n",
        "})\n"
      ],
      "metadata": {
        "id": "dJLL73PMnT35"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}